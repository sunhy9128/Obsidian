#ML 
### 1. 最近邻算法 KNN(k-nearest neighbor)

-   欧氏距离

$$d(x_A,x_b)=\sqrt{\sum_{k=1}^n({x_A-x_b}})^2$$

```python
def classifyKNN(test,dataset,k):
    result=[]
    dist=list((((dataset.iloc[:6,1:3]-test)**2).sum(1))**.5)
    dist_sort=pd.DataFrame({'dist':dist,'labels':(dataset.iloc[:6,3])}).sort_values(by='dist')[:k]
    re=dist_sort.loc[:,'labels'].value_counts()
    result.append(re.index[0])
    return result
```

### 2. 决策树DecisionTree

信息熵（香农熵）、Gini不纯度

$$Gini(p)=1-\sum_{i=1}^np_i^2$$

$$Entropy=-\sum_{i=1}^np_ilog_2{p_i}$$

香农熵在低级泰勒展开近似等于Gini不纯度

```python
def calculateshang(data):
    names = data.iloc[:, -1]
    n = len(names)
    labels = {}
    for i, j in names.value_counts().items():
        labels[i] = j
    shang = 0
    for i in labels:
        pi = labels[i]/n
        shang -= pi*log(pi, 2)
    return shang
```

信息熵和Gini不纯度用于选择最佳切分点

### 3. 朴素贝叶斯

$$P(A|B)=P(A)\frac{P(B|A)}{P(B)}$$

$$其中\ P(B)=\sum_{i=1}^{n}P(A_i)P(B|A_i)$$

A：嫁/不嫁

B：性格好/性格不好；帅/不帅；上进/不上进

$$P(嫁｜帅\ 性格不好\ 不上进)=P(嫁)\frac{P(帅|嫁)P(性格不好|嫁)P(不上进|嫁 )}{P(帅\ 性格不好\ 不上进)}$$

$$其中\ P(帅\ 性格不好\ 不上进)=P(嫁)P(帅| 嫁)P(性格不好|嫁)P(不上进|嫁)+P(不嫁)P(帅 |不嫁)P(性格不好|不嫁)P(不上进|不嫁)$$